{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nnames=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\ndf=pd.read_csv('../input/iris.data.txt',header=None,names=names)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotnine as p9\n(p9.ggplot(data=df,mapping=p9.aes(x='sepal_length',y='sepal_width',color= 'class'))\n+p9.geom_point()\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(p9.ggplot(data=df,mapping=p9.aes(x='petal_length',y='petal_width',color='class'))\n+p9.geom_point()\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = np.array(df.iloc[:, 0:4])\ny = np.array(df['class'])\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining clssifiers.Fit the model for KNN using any K value"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nknn=KNeighborsClassifier(n_neighbors=3)\nknn.fit(x_train,y_train)\npred=knn.predict(x_test)\nprint(accuracy_score(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A 10 Fold cross validation using a list of odd K's ranging from 1 to 50"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import cross_val_score\nmylist=list(range(1,50))\nneighbor=list(filter(lambda x:x%2 !=0,mylist))\ncvscore=[]\nfor k in neighbor:\n    knn=KNeighborsClassifier(n_neighbors=k)\n    scores=cross_val_score(knn,x_train,y_train,cv=10,scoring='accuracy')\n    cvscore.append(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To find the misclassification error"},{"metadata":{"trusted":true},"cell_type":"code","source":"MSE=[1-x for x in cvscore]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get the minimum MSE for optimal K"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_k=neighbor[MSE.index(min(MSE))]\nprint(\"the optimal number of neighbors is\",optimal_k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(neighbor,MSE)\nplt.xlabel('Number of Neighbor of K')\nplt.ylabel('Misclassifcation Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hereby We can se that K=7 gives us the lowest validation error"},{"metadata":{},"cell_type":"markdown","source":"# Writting Own KNN function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(x_train,y_train):\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ndef predict(x_train,y_train,x_test,k):\n    distance=[]\n    target=[]\n    for i in range(len(x_train)):\n        dist=np.sqrt(np.sum(np.square(x_test - x_train[i,:])))\n        distance.append([dist,i])\n    distance=sorted(distance)\n    for i in range(k):\n        index=distance[i][1]\n        target.append(y_train[index])\n    return Counter(target).most_common(1)[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def KNearestNeighbor(x_train,y_train,x_test,prediction,k):\n    if(k>len(x_train)):\n        raise ValueError\n        \n    train(x_train,y_train)\n    \n   #For all observation\n    for i in range(len(x_test)):\n        prediction.append(predict(x_train,y_train,x_test[i,:],k))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=[]\ntry:\n    KNearestNeighbor(x_train,y_train,x_test,predictions,7)\n    #List to array\n    predictions=np.asarray(predictions)\n    #Accuracy\n    accuracy=accuracy_score(y_test,predictions)\n    print('The accuracy of the classifier is',accuracy*100 , '%')\nexcept ValueError:\n    print(\"Can't have more neighbor than training samples!!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}